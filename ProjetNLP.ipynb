{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetNLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antoine723/ProjetNLP/blob/main/ProjetNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLK8-Mgvzzrg",
        "outputId": "4ed37bef-8b55-46f4-a341-ed325cdeb5f3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN10vLT_0P2y",
        "outputId": "4cdbd780-467a-4d4c-9d66-bbeaec565364"
      },
      "source": [
        "import pandas as pd\r\n",
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.text import Text\r\n",
        "from nltk.stem.lancaster import LancasterStemmer\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from gdrive.MyDrive.ProjetNLP.rnn_utils import *\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzY87idiwDd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf2b3d1-5107-4179-cc58-35c0d25b298f"
      },
      "source": [
        "df=pd.read_csv('gdrive/MyDrive/ProjetNLP/training.1600000.processed.noemoticon.csv',encoding=\"ISO-8859-1\",header=None)\r\n",
        "data=np.array([df.iloc[0:5][5],df.iloc[800000:800005][5]])\r\n",
        "\r\n",
        "print(data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
            "  \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"\n",
            "  '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds'\n",
            "  'my whole body feels itchy and like its on fire '\n",
            "  \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"]\n",
            " ['I LOVE @Health4UandPets u guys r the best!! '\n",
            "  'im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!'\n",
            "  '@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart. '\n",
            "  'Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup'\n",
            "  '@LovesBrooklyn2 he has that effect on everyone ']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B-hOwDR3sIq"
      },
      "source": [
        "# Traitement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF6A8FMM47E9"
      },
      "source": [
        "def processing(data):\r\n",
        "\r\n",
        "  #MINUSCULES\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      data[i][j]=data[i][j].lower()\r\n",
        "  # print(data)\r\n",
        "\r\n",
        "  #TOKENIZATION\r\n",
        "  tokenizer = nltk.RegexpTokenizer(r'\\w+')\r\n",
        "\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      data[i][j]=tokenizer.tokenize(data[i][j])\r\n",
        "  # print(data)\r\n",
        "\r\n",
        "  #STOPWORDS\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      data[i][j]=[w for w in data[i][j] if not w in list(nltk.corpus.stopwords.words('english'))]\r\n",
        "      \r\n",
        "  # print(data)\r\n",
        "\r\n",
        "  #STEMMING\r\n",
        "  stemmer=LancasterStemmer()\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      data[i][j]=[stemmer.stem(w) for w in data[i][j]]\r\n",
        "  # print(data)\r\n",
        "\r\n",
        "  #LEMMATIZATION\r\n",
        "  Word_Lemmatizer = WordNetLemmatizer()\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      data[i][j]=[Word_Lemmatizer.lemmatize(w) for w in data[i][j]]\r\n",
        "  print(data)\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGs2Q81z4RKN",
        "outputId": "19554e39-1725-43b8-c650-0f1d590c0452"
      },
      "source": [
        "datas=processing(data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[list(['switchfoot', 'http', 'twitp', 'com', '2y1zl', 'awww', 'bum', 'should', 'got', 'david', 'car', 'third', 'day'])\n",
            "  list(['upset', 'upd', 'facebook', 'text', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah'])\n",
            "  list(['kenich', 'div', 'many', 'tim', 'bal', 'man', 'sav', '50', 'rest', 'go', 'bound'])\n",
            "  list(['whol', 'body', 'feel', 'itchy', 'lik', 'fir'])\n",
            "  list(['nationwideclass', 'behav', 'mad', 'see'])]\n",
            " [list(['lov', 'health4uandpets', 'u', 'guy', 'r', 'best'])\n",
            "  list(['im', 'meet', 'on', 'besty', 'tonight', 'cant', 'wait', 'girl', 'talk'])\n",
            "  list(['darealsunisakim', 'thank', 'twit', 'ad', 'sunis', 'got', 'meet', 'hin', 'show', 'dc', 'are', 'sweetheart'])\n",
            "  list(['sick', 'real', 'cheap', 'hurt', 'much', 'eat', 'real', 'food', 'plu', 'friend', 'mak', 'soup'])\n",
            "  list(['lovesbrooklyn2', 'effect', 'everyon'])]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykywsQVzQfCE",
        "outputId": "280e8cc2-5185-4ee0-8b4c-5871c88f3a50"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "v=set()\r\n",
        "for i in range(len(data)):\r\n",
        "  for j in range(len(data[i])):\r\n",
        "    for h in range(len(data[i][j])):\r\n",
        "      v.add(data[i][j][h])\r\n",
        "\r\n",
        "vocab = defaultdict(lambda: 0)\r\n",
        "vocab['<PAD>'] = 1\r\n",
        "\r\n",
        "j=2\r\n",
        "for i in v:\r\n",
        "  vocab[i]=j\r\n",
        "  j+=1\r\n",
        "print(vocab)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function <lambda> at 0x7f6c5e53d400>, {'<PAD>': 1, 'im': 2, 'kenich': 3, 'sweetheart': 4, 'result': 5, 'feel': 6, 'show': 7, 'sav': 8, 'whol': 9, 'hurt': 10, 'might': 11, 'girl': 12, '2y1zl': 13, 'switchfoot': 14, 'bum': 15, 'mad': 16, 'meet': 17, 'u': 18, 'ad': 19, 'david': 20, 'third': 21, 'twit': 22, 'div': 23, 'com': 24, 'on': 25, '50': 26, 'go': 27, 'upd': 28, 'food': 29, 'mak': 30, 'fir': 31, 'body': 32, 'health4uandpets': 33, 'darealsunisakim': 34, 'blah': 35, 'tim': 36, 'also': 37, 'facebook': 38, 'lik': 39, 'behav': 40, 'man': 41, 'cant': 42, 'see': 43, 'day': 44, 'best': 45, 'sick': 46, 'twitp': 47, 'real': 48, 'should': 49, 'cheap': 50, 'soup': 51, 'effect': 52, 'everyon': 53, 'dc': 54, 'eat': 55, 'upset': 56, 'text': 57, 'itchy': 58, 'thank': 59, 'hin': 60, 'many': 61, 'lov': 62, 'plu': 63, 'sunis': 64, 'awww': 65, 'tonight': 66, 'friend': 67, 'r': 68, 'much': 69, 'cry': 70, 'are': 71, 'lovesbrooklyn2': 72, 'talk': 73, 'besty': 74, 'bal': 75, 'school': 76, 'got': 77, 'car': 78, 'today': 79, 'http': 80, 'wait': 81, 'bound': 82, 'rest': 83, 'guy': 84, 'nationwideclass': 85})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9z0zbQbO31u"
      },
      "source": [
        "def transformWords(data):\r\n",
        "  matrixData=[]\r\n",
        "  maxLen=0\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      if (maxLen < len(data[i][j])):\r\n",
        "        maxLen= len(data[i][j])\r\n",
        "\r\n",
        "  for i in range(len(data)):\r\n",
        "    for j in range(len(data[i])):\r\n",
        "      test=[]\r\n",
        "      for k in range(maxLen):\r\n",
        "        if (k >= len(data[i][j])):\r\n",
        "          test.append(vocab['<PAD>'])\r\n",
        "        else:\r\n",
        "          test.append(vocab[data[i][j][k]])\r\n",
        "      matrixData.append(test)\r\n",
        "  return matrixData"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyL0yeQLJeUW",
        "outputId": "a24d4183-e9bd-41ea-d944-6998fb057564"
      },
      "source": [
        "data=transformWords(data)\r\n",
        "datas=np.array([df.iloc[5:10][5],df.iloc[800005:800010][5]])\r\n",
        "datas=processing(datas)\r\n",
        "datas=transformWords(datas)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[list(['kweside', 'whol', 'crew']) list(['nee', 'hug'])\n",
            "  list(['lolt', 'hey', 'long', 'tim', 'see', 'ye', 'rain', 'bit', 'bit', 'lol', 'fin', 'thank'])\n",
            "  list(['tatiana_k', 'nop']) list(['twitter', 'que', 'muer'])]\n",
            " [list(['productoffear', 'tel', 'burst', 'laugh', 'real', 'loud', 'thank', 'mak', 'com', 'sulk'])\n",
            "  list(['r_keith_hill', 'than', 'respons', 'ihad', 'already', 'find', 'answ'])\n",
            "  list(['keepinupwkr', 'jeal', 'hop', 'gre', 'tim', 'vega', 'lik', 'acm', 'lov', 'show'])\n",
            "  list(['tommcf', 'ah', 'congr', 'mr', 'fletch', 'fin', 'join', 'twit'])\n",
            "  list(['e4voip', 'respond', 'stupid', 'cat', 'help', 'typ', 'forg', 'er'])]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e6eAwEM8HIB"
      },
      "source": [
        "model=tf.keras.Sequential()\r\n",
        "model.add(tf.keras.layers.Embedding(input_dim=len(vocab),output_dim=2))\r\n",
        "model.add(tf.keras.layers.LSTM(128,activation=\"relu\"))\r\n",
        "model.add(tf.keras.layers.Dense(1,activation=\"softmax\"))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTolxgL4qTYv"
      },
      "source": [
        "data=np.array(data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC2K0b31qXIJ",
        "outputId": "a1726fbc-cd48-42fb-a541-dd2ebf7160a4"
      },
      "source": [
        "data"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14, 80, 47, 24, 13, 65, 15, 49, 77, 20, 78, 21, 44],\n",
              "       [56, 28, 38, 57, 11, 70,  5, 76, 79, 37, 35,  1,  1],\n",
              "       [ 3, 23, 61, 36, 75, 41,  8, 26, 83, 27, 82,  1,  1],\n",
              "       [ 9, 32,  6, 58, 39, 31,  1,  1,  1,  1,  1,  1,  1],\n",
              "       [85, 40, 16, 43,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
              "       [62, 33, 18, 84, 68, 45,  1,  1,  1,  1,  1,  1,  1],\n",
              "       [ 2, 17, 25, 74, 66, 42, 81, 12, 73,  1,  1,  1,  1],\n",
              "       [34, 59, 22, 19, 64, 77, 17, 60,  7, 54, 71,  4,  1],\n",
              "       [46, 48, 50, 10, 69, 55, 48, 29, 63, 67, 30, 51,  1],\n",
              "       [72, 52, 53,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0yR14U9WHfr"
      },
      "source": [
        "datas=np.array(datas)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFaMVFSxZHcH",
        "outputId": "15271ad4-dd08-45cd-ac8b-8cc19f157d7a"
      },
      "source": [
        "print(data)\r\n",
        "print(datas)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14 80 47 24 13 65 15 49 77 20 78 21 44]\n",
            " [56 28 38 57 11 70  5 76 79 37 35  1  1]\n",
            " [ 3 23 61 36 75 41  8 26 83 27 82  1  1]\n",
            " [ 9 32  6 58 39 31  1  1  1  1  1  1  1]\n",
            " [85 40 16 43  1  1  1  1  1  1  1  1  1]\n",
            " [62 33 18 84 68 45  1  1  1  1  1  1  1]\n",
            " [ 2 17 25 74 66 42 81 12 73  1  1  1  1]\n",
            " [34 59 22 19 64 77 17 60  7 54 71  4  1]\n",
            " [46 48 50 10 69 55 48 29 63 67 30 51  1]\n",
            " [72 52 53  1  1  1  1  1  1  1  1  1  1]]\n",
            "[[ 0  9  0  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  0  1  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  0  0 36 43  0  0  0  0  0  0 59]\n",
            " [ 0  0  1  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  0  0  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  0  0  0 48  0 59 30 24  0  1  1]\n",
            " [ 0  0  0  0  0  0  0  1  1  1  1  1]\n",
            " [ 0  0  0  0 36  0 39  0 62  7  1  1]\n",
            " [ 0  0  0  0  0  0  0 22  1  1  1  1]\n",
            " [ 0  0  0  0  0  0  0  0  1  1  1  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYX8kcYATLQg",
        "outputId": "db046641-c07c-457e-a6b6-e561f41c0ba9"
      },
      "source": [
        "y_train=np.concatenate([np.zeros((5,1)),np.ones((5,1))])\r\n",
        "model.compile(loss='binary_crossentropy',optimizer=\"sgd\")\r\n",
        "model.fit(data,y_train,validation_data=(datas,y_train),epochs=50)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6931 - val_loss: 0.6931\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6931 - val_loss: 0.6931\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6930 - val_loss: 0.6931\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6930 - val_loss: 0.6931\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6930 - val_loss: 0.6931\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6930 - val_loss: 0.6931\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6930 - val_loss: 0.6931\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6930 - val_loss: 0.6932\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6930 - val_loss: 0.6932\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6930 - val_loss: 0.6932\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6930 - val_loss: 0.6932\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6930 - val_loss: 0.6932\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6929 - val_loss: 0.6932\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6929 - val_loss: 0.6933\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6929 - val_loss: 0.6933\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6928 - val_loss: 0.6933\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6927 - val_loss: 0.6933\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6927 - val_loss: 0.6933\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6927 - val_loss: 0.6933\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6927 - val_loss: 0.6933\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6927 - val_loss: 0.6933\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6927 - val_loss: 0.6934\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6927 - val_loss: 0.6934\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6927 - val_loss: 0.6934\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6927 - val_loss: 0.6934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6c69cb6198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZJHW75PqsU2",
        "outputId": "da372eb0-dad2-490c-8159-051b1b3280e3"
      },
      "source": [
        "model.predict(data[0])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}